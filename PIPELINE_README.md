# OpenSSH Log Processing Pipeline

## ğŸ“‹ Overview

This is a **3-layer data pipeline** (Bronze â†’ Silver â†’ Gold) that processes OpenSSH log files using **PySpark**.

### Pipeline Layers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Log File (logs/OpenSSH_2k.log)                         â”‚
â”‚  - Unstructured text logs                                   â”‚
â”‚  - 2000 OpenSSH authentication events                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BRONZE LAYER (scripts/bronze/raw_load.py)                  â”‚
â”‚  - Load raw logs as-is                                      â”‚
â”‚  - Save to Parquet format                                   â”‚
â”‚  - Output: data/bronze/raw_logs.parquet                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SILVER LAYER (scripts/silver/silver_load.py)               â”‚
â”‚  - Parse log format                                         â”‚
â”‚  - Extract: Date, Day, Time, Component, Pid, Content        â”‚
â”‚  - Generate: EventId, EventTemplate                         â”‚
â”‚  - Apply quality checks                                     â”‚
â”‚  - Save to JSON format                                      â”‚
â”‚  - Output: data/silver/structured_logs.json                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GOLD LAYER (scripts/gold/gold_load.py)                     â”‚
â”‚  - Combine Date+Day+Time â†’ datetime                         â”‚
â”‚  - Filter quality-passed records                            â”‚
â”‚  - Save to CSV format                                       â”‚
â”‚  - Output: data/gold/openssh_logs_final.csv                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ Project Structure

```
contextq/
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ OpenSSH_2k.log                    # Source log file (2000 lines)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â””â”€â”€ raw_load.py                   # Bronze layer: Raw load
â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â””â”€â”€ silver_load.py                # Silver layer: Parse & transform
â”‚   â”œâ”€â”€ gold/
â”‚   â”‚   â””â”€â”€ gold_load.py                  # Gold layer: Final curated
â”‚   â””â”€â”€ run_pipeline.py                   # Master pipeline runner
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â””â”€â”€ raw_logs.parquet              # Raw logs in Parquet
â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â””â”€â”€ structured_logs.json          # Parsed & validated JSON
â”‚   â””â”€â”€ gold/
â”‚       â””â”€â”€ openssh_logs_final.csv        # Final curated CSV
â”‚
â””â”€â”€ Data_file/
    â””â”€â”€ OpenSSH_2k.log_structured.csv     # Reference format
```

---

## ğŸš€ Quick Start

### 1. Run Complete Pipeline

```bash
# Run all layers (Bronze â†’ Silver â†’ Gold)
python scripts/run_pipeline.py
```

### 2. Run Individual Layers

```bash
# Run only Bronze layer
python scripts/run_pipeline.py --layer bronze

# Run only Silver layer (requires Bronze to be run first)
python scripts/run_pipeline.py --layer silver

# Run only Gold layer (requires Silver to be run first)
python scripts/run_pipeline.py --layer gold
```

### 3. Run Scripts Directly

```bash
# Bronze layer
python scripts/bronze/raw_load.py

# Silver layer
python scripts/silver/silver_load.py

# Gold layer
python scripts/gold/gold_load.py
```

---

## ğŸ“Š Data Transformation Details

### Bronze Layer

**Input**: `logs/OpenSSH_2k.log`
```
Dec 10 06:55:46 LabSZ sshd[24200]: Invalid user webmaster from 173.234.31.186
```

**Output**: `data/bronze/raw_logs.parquet`
```
| LineId | raw_log                                                      | ingestion_timestamp     | source_file          |
|--------|--------------------------------------------------------------|-------------------------|----------------------|
| 1      | Dec 10 06:55:46 LabSZ sshd[24200]: Invalid user webmaster...| 2025-10-16 19:30:00    | logs/OpenSSH_2k.log  |
```

---

### Silver Layer

**Transformations**:
1. **Parse log fields**:
   - Date (month): `Dec`
   - Day: `10`
   - Time: `06:55:46`
   - Component: `LabSZ`
   - Pid: `24200`
   - Content: `Invalid user webmaster from 173.234.31.186`

2. **Generate event patterns**:
   - EventId: `E13`
   - EventTemplate: `Invalid user <*> from <*>`

3. **Quality checks**:
   - Completeness check
   - Time format validation
   - PID validation
   - Month validation

**Output**: `data/silver/structured_logs.json`
```json
{
  "LineId": 1,
  "Date": "Dec",
  "Day": "10",
  "Time": "06:55:46",
  "Component": "LabSZ",
  "Pid": "24200",
  "Content": "Invalid user webmaster from 173.234.31.186",
  "EventId": "E13",
  "EventTemplate": "Invalid user <*> from <*>",
  "overall_quality": "PASS"
}
```

---

### Gold Layer

**Transformations**:
1. **Combine datetime**: `Date + Day + Time` â†’ `10-Dec-2024 : 06:55:46`
2. **Remove**: Original `Date`, `Day`, `Time` columns
3. **Filter**: Keep only quality-passed records

**Output**: `data/gold/openssh_logs_final.csv`
```csv
LineId,datetime,Component,Pid,EventId,EventTemplate,Content
1,10-Dec-2024 : 06:55:46,LabSZ,24200,E13,Invalid user <*> from <*>,Invalid user webmaster from 173.234.31.186
```

---

## ğŸ” Data Quality Checks (Silver Layer)

The Silver layer applies comprehensive quality checks:

| Check | Description | Action |
|-------|-------------|--------|
| **Completeness** | Ensure required fields are not null/empty | Flag as FAIL |
| **Time Format** | Validate HH:MM:SS format | Flag as FAIL |
| **PID Validation** | Ensure PID is numeric | Flag as FAIL |
| **Month Validation** | Check valid month abbreviation | Flag as FAIL |
| **Overall Quality** | All checks must PASS | Filter in Gold layer |

---

## ğŸ“ˆ Event Categories

The pipeline recognizes these SSH event patterns:

| EventId | Event Type | Example |
|---------|-----------|---------|
| E27 | Reverse mapping check failed | `POSSIBLE BREAK-IN ATTEMPT!` |
| E13 | Invalid user | `Invalid user webmaster` |
| E12 | Invalid user auth request | `input_userauth_request: invalid user` |
| E21 | User unknown | `check pass; user unknown` |
| E19 | Authentication failure | `authentication failure` |
| E10 | Failed password (invalid user) | `Failed password for invalid user` |
| E2 | Connection closed | `Connection closed by` |
| E24 | Disconnect received | `Received disconnect` |
| E9 | Failed password | `Failed password for` |
| E18 | Accepted password | `Accepted password for` |

---

## ğŸ’¾ Output Formats

| Layer | Format | Why? |
|-------|--------|------|
| **Bronze** | Parquet | Columnar storage, compressed, fast read |
| **Silver** | JSON | Flexible schema, human-readable, queryable |
| **Gold** | CSV | Business-friendly, Excel-compatible, portable |

---

## ğŸ”§ Technical Details

### PySpark Configuration

Each layer uses PySpark with:
- **Master**: `local[*]` (all available cores)
- **Memory**: 2GB driver memory
- **App Name**: Layer-specific names

### Processing Mode

- **Bronze**: Append-only, immutable raw data
- **Silver**: Overwrite mode with quality filtering
- **Gold**: Overwrite mode with curated data

### Error Handling

- Bronze failures stop the pipeline
- Silver failures are logged with quality flags
- Gold only processes quality-passed records

---

## ğŸ“ Example: Running the Pipeline

```bash
$ python scripts/run_pipeline.py

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â–ˆ                                                                              â–ˆ
â–ˆ                  OpenSSH Log Processing Pipeline                            â–ˆ
â–ˆ                      Bronze â†’ Silver â†’ Gold                                 â–ˆ
â–ˆ                                                                              â–ˆ
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

Pipeline started at: 2025-10-16 19:30:00
Layers to run: BRONZE, SILVER, GOLD

==============================================================================
  Running BRONZE Layer
==============================================================================
Script: scripts/bronze/raw_load.py
...

âœ… BRONZE layer completed successfully

==============================================================================
  Running SILVER Layer
==============================================================================
...

âœ… SILVER layer completed successfully

==============================================================================
  Running GOLD Layer
==============================================================================
...

âœ… GOLD layer completed successfully

==============================================================================
  PIPELINE SUMMARY
==============================================================================
Start Time:    2025-10-16 19:30:00
End Time:      2025-10-16 19:30:45
Duration:      0:00:45
Status:        âœ… SUCCESS
==============================================================================

ğŸ‰ Pipeline completed successfully!

Output locations:
  ğŸ“ Bronze: data/bronze/raw_logs.parquet
  ğŸ“ Silver: data/silver/structured_logs.json
  ğŸ“ Gold:   data/gold/openssh_logs_final.csv
```

---

## ğŸ› Troubleshooting

### Issue: Java not found

```bash
# Install Java 11
brew install openjdk@11

# Set JAVA_HOME
export JAVA_HOME=/opt/homebrew/opt/openjdk@11
```

### Issue: PySpark not installed

```bash
pip install pyspark==3.4.1
```

### Issue: Bronze data not found

Make sure to run Bronze layer first:
```bash
python scripts/run_pipeline.py --layer bronze
```

---

## ğŸ“š Documentation

- **LOG_FORMAT.md** - Log format specification
- **DATA_PIPELINE_STATUS.md** - Pipeline status and architecture
- **AZURE_ARCHITECTURE_PLAN.md** - Azure deployment plan

---

## âœ… Success Criteria

- âœ… Bronze: 2000 raw log lines converted to Parquet
- âœ… Silver: All 2000 lines parsed with quality checks
- âœ… Gold: ~1900-2000 quality-passed records in CSV
- âœ… datetime field combines Date+Day+Time correctly
- âœ… Original Date, Day, Time columns removed in Gold

---

## ğŸ¯ Next Steps

1. âœ… Local pipeline complete
2. ğŸ”„ Deploy to Azure Databricks
3. â³ Orchestrate with Azure Data Factory
4. â³ Add ML model training (anomaly detection)
5. â³ Set up CI/CD pipeline

---

**Created**: October 16, 2025  
**Pipeline Version**: 1.0  
**Author**: Data Engineering Team

