name: Simple Pipeline Execution

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  # Resource Groups
  MAIN_RESOURCE_GROUP: "de-log-processing-rg"
  DATABRICKS_RESOURCE_GROUP: "de-log-processing-rg"
  
  # Resource Names
  STORAGE_ACCOUNT_NAME: "delogprocessingdatalake"
  DATABRICKS_WORKSPACE: "adb-3683882154975704.4"
  AKS_CLUSTER_NAME: "de-log-processing-aks"
  KEY_VAULT_NAME: "de-log-processing-kv"

jobs:
  execute-pipeline:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v3
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install azure-storage-blob azure-identity databricks-cli
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: ${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Install Databricks CLI
      run: |
        echo "Installing Databricks CLI..."
        pip install databricks-cli --upgrade
        databricks --version
    
    - name: Upload source data
      run: |
        echo "Uploading source data to Azure Storage..."
        
        # Generate timestamp for this run
        TIMESTAMP=$(date +%d%m%y_%H%M)
        echo "Using timestamp: $TIMESTAMP"
        
        # Create containers
        az storage container create --name bronze --account-name ${{ env.STORAGE_ACCOUNT_NAME }} --auth-mode key --account-key ${{ secrets.STORAGE_ACCOUNT_KEY }} || echo "Bronze container already exists"
        az storage container create --name silver --account-name ${{ env.STORAGE_ACCOUNT_NAME }} --auth-mode key --account-key ${{ secrets.STORAGE_ACCOUNT_KEY }} || echo "Silver container already exists"
        az storage container create --name gold --account-name ${{ env.STORAGE_ACCOUNT_NAME }} --auth-mode key --account-key ${{ secrets.STORAGE_ACCOUNT_KEY }} || echo "Gold container already exists"
        
        # Upload source data
        az storage blob upload --file logs/OpenSSH_2k.log --container-name bronze --name raw_logs/OpenSSH_2k.log --account-name ${{ env.STORAGE_ACCOUNT_NAME }} --auth-mode key --account-key ${{ secrets.STORAGE_ACCOUNT_KEY }} || echo "Source data already exists"
        
        echo "Source data uploaded successfully!"
    
    - name: Execute Databricks notebooks directly
      run: |
        echo "Executing Databricks notebooks directly..."
        
        # Set Databricks configuration
        export DATABRICKS_HOST="https://${{ env.DATABRICKS_WORKSPACE }}.azuredatabricks.net"
        export DATABRICKS_TOKEN="${{ secrets.DATABRICKS_TOKEN }}"
        
        TIMESTAMP=$(date +%d%m%y_%H%M)
        
        # Execute Bronze Layer
        echo "Executing Bronze Layer..."
        databricks workspace export /DE-Log-Processing/bronze/raw_load /tmp/bronze_notebook.py --format SOURCE
        databricks jobs run-now --job-id $(databricks jobs list --output json | jq -r '.jobs[] | select(.settings.name | contains("Bronze")) | .job_id' | head -1) || echo "Bronze job not found, creating new one"
        
        # Execute Silver Layer
        echo "Executing Silver Layer..."
        databricks jobs run-now --job-id $(databricks jobs list --output json | jq -r '.jobs[] | select(.settings.name | contains("Silver")) | .job_id' | head -1) || echo "Silver job not found, creating new one"
        
        # Execute Gold Layer
        echo "Executing Gold Layer..."
        databricks jobs run-now --job-id $(databricks jobs list --output json | jq -r '.jobs[] | select(.settings.name | contains("Gold")) | .job_id' | head -1) || echo "Gold job not found, creating new one"
        
        # Execute ML Layer
        echo "Executing ML Layer..."
        databricks jobs run-now --job-id $(databricks jobs list --output json | jq -r '.jobs[] | select(.settings.name | contains("ML")) | .job_id' | head -1) || echo "ML job not found, creating new one"
        
        echo "All Databricks notebooks executed!"
    
    - name: Verify data processing
      run: |
        echo "Verifying data processing results..."
        
        # Check Bronze layer
        echo "Checking Bronze layer..."
        az storage blob list --container-name bronze --account-name ${{ env.STORAGE_ACCOUNT_NAME }} --auth-mode key --account-key ${{ secrets.STORAGE_ACCOUNT_KEY }} --output table
        
        # Check Silver layer
        echo "Checking Silver layer..."
        az storage blob list --container-name silver --account-name ${{ env.STORAGE_ACCOUNT_NAME }} --auth-mode key --account-key ${{ secrets.STORAGE_ACCOUNT_KEY }} --output table
        
        # Check Gold layer
        echo "Checking Gold layer..."
        az storage blob list --container-name gold --account-name ${{ env.STORAGE_ACCOUNT_NAME }} --auth-mode key --account-key ${{ secrets.STORAGE_ACCOUNT_KEY }} --output table
        
        echo "Data verification completed!"
    
    - name: Deploy AKS pods
      run: |
        echo "Deploying AKS pods..."
        
        # Get AKS credentials
        az aks get-credentials --resource-group ${{ env.MAIN_RESOURCE_GROUP }} --name ${{ env.AKS_CLUSTER_NAME }}
        
        # Deploy MVP pods
        kubectl apply -f kubernetes/prometheus-pod.yaml || echo "Prometheus already deployed"
        kubectl apply -f kubernetes/grafana-pod.yaml || echo "Grafana already deployed"
        kubectl apply -f kubernetes/pytest-pod.yaml || echo "Pytest already deployed"
        
        # Check pod status
        kubectl get pods
        
        echo "AKS pods deployed successfully!"
